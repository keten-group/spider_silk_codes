{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import csv\n",
    "from numpy import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import date\n",
    "import json\n",
    "# mpl.rcParams['figure.dpi'] = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique amino acids are 21\n"
     ]
    }
   ],
   "source": [
    "# # different amino acids\n",
    "amino_acid = ['A', 'V', 'F', 'I', 'L','D','E','K','S','T','Y','C','N','Q', 'P','M', 'R', 'H', 'W', 'G','X'] # X is the undetermined amino acid, so total length is 21\n",
    "print('Number of unique amino acids are', np.shape(np.unique(amino_acid))[0])\n",
    "\n",
    "def onehotseq(sequence):\n",
    "  seq_len = np.shape(sequence)[0]\n",
    "  # print('Seq len is', seq_len)\n",
    "  seq_en = np.zeros(( seq_len, np.shape(amino_acid)[0]))\n",
    "  for i in range(seq_len):\n",
    "    if sequence[i] in amino_acid:\n",
    "      pos = amino_acid.index(sequence[i])\n",
    "      seq_en[i,pos] = 1\n",
    "    else:\n",
    "      pos = amino_acid.index('X')\n",
    "      seq_en[i,pos] = 1\n",
    "\n",
    "  return seq_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input sequence data\n",
    "def one_hot_encoding(input_sequence, num_files, seq_length):\n",
    "    ohe = np.zeros((input_sequence.shape[0], input_sequence.shape[1],input_sequence.shape[2], len(amino_acid)))\n",
    "\n",
    "    for i in range(input_sequence.shape[0]):\n",
    "        for j in range(input_sequence.shape[1]):\n",
    "            seq_len = int(seq_length[i,j])\n",
    "            if seq_len > 0:\n",
    "                seq_en = onehotseq(input_sequence[i,j,0:seq_len])\n",
    "                ohe[i,j,0:seq_len,:] = seq_en\n",
    "    return ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (bnn1): Linear(in_features=21, out_features=32, bias=True)\n",
       "  (bnn2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (bnn3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (bnn4): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (lstm1): LSTM(64, 512, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (bn_lstm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (nn1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (nn2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (nn3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (nn4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (nn5): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (nn6): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (nn7): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (nn8): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# LSTM Model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_layers, seq_len,num_classes=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.bnn1 = nn.Linear(input_size, 32)\n",
    "        self.bnn2 = nn.Linear(32,64)\n",
    "        self.bnn3 = nn.Linear(64,64)\n",
    "        self.bnn4 = nn.Linear(64,64)\n",
    "\n",
    "        self.lstm1 = nn.LSTM(64, hidden_size1, num_layers, batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        self.bn_lstm1 = nn.BatchNorm1d(2*hidden_size1,device=device)  \n",
    "        # self.lstm2 = nn.LSTM(2*hidden_size1, hidden_size2, num_layers, batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        # self.bn_lstm2 = nn.BatchNorm1d(2*hidden_size2,device=device)\n",
    "        self.nn1 = nn.Linear(2*hidden_size1, 2*hidden_size1)\n",
    "        self.nn2 = nn.Linear(2*hidden_size1, 512)\n",
    "        self.nn3 = nn.Linear(512, 512)\n",
    "        self.nn4 = nn.Linear(512, 256)\n",
    "        self.nn5 = nn.Linear(256, 256)\n",
    "        self.nn6 = nn.Linear(256, 128)\n",
    "        self.nn7 = nn.Linear(128, 32)\n",
    "        self.nn8 = nn.Linear(32, 1)\n",
    "\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        # self.batch = nn.BatchNorm1d()\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x, array_lengths):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        # print(x.size(0))\n",
    "        inital_seq_len = x.size(1)\n",
    "        x = Variable(x.float()).to(device)\n",
    "\n",
    "        x = torch.reshape(x, (x.size(0)*x.size(1), x.size(2)))\n",
    "\n",
    "        ## before nn\n",
    "        out = self.bnn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bnn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.bnn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.bnn4(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        ## reshaping again\n",
    "        out = torch.reshape(out, (-1, inital_seq_len, out.size(1)))\n",
    "        # print(out.size())\n",
    "        # print(aaaaa)\n",
    "\n",
    "        # out = torch.permute(out, (0,2,1))\n",
    "        \n",
    "        pack = nn.utils.rnn.pack_padded_sequence(out, array_lengths, batch_first=True, enforce_sorted=False)\n",
    "        h0 = Variable(torch.zeros(2*self.num_layers, x.size(0), self.hidden_size1).to(device))\n",
    "        c0 = Variable(torch.zeros(2*self.num_layers, x.size(0), self.hidden_size1).to(device))\n",
    "        h1 = Variable(torch.zeros(2*self.num_layers, self.hidden_size1, self.hidden_size2).to(device))\n",
    "        c1 = Variable(torch.zeros(2*self.num_layers, self.hidden_size1, self.hidden_size2).to(device))\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm1(pack, (h0,c0))\n",
    "        del(h0)\n",
    "        del(c0)\n",
    "        # out, _ = self.lstm2(out, (h1,c1))\n",
    "        gc.collect()\n",
    "        unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        this_batch_len = unpacked.size(1)\n",
    "        out = unpacked\n",
    "        # print('before', out.size())\n",
    "        out = torch.reshape(out, (out.size(0)*out.size(1), out.size(2)))\n",
    "\n",
    "        ##nn\n",
    "        out = self.nn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.nn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.nn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.nn4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.nn5(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.nn6(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.nn7(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.nn8(out)\n",
    "        \n",
    "        ## reshaping\n",
    "        out = torch.reshape(out, (-1, this_batch_len, 1))\n",
    "        # print(out.size()) \n",
    "        # print(aaaaa)   \n",
    "        \n",
    "\n",
    "        return out\n",
    "\n",
    "model_test = torch.load('../b_factor_model.pth', map_location='cuda:2')\n",
    "model_test.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_factor_cal(ohe, num_files, seq_length):\n",
    "  \n",
    "  b_factor = np.zeros((ohe.shape[0], ohe.shape[1], ohe.shape[2]))\n",
    "  ohe = torch.from_numpy(ohe).to(device)\n",
    "  # max_seq_len = int(np.max(seq_length))\n",
    "  # print(max_len)\n",
    "  with torch.no_grad():\n",
    "    for i in range(ohe.shape[0]):\n",
    "      if int(num_files[i,]) !=0:\n",
    "        input_x = ohe[i,0:int(num_files[i,]),:,:]        \n",
    "        input_x = torch.reshape(input_x, (input_x.shape[0],int(np.max(seq_length)),len(amino_acid)))  \n",
    "        # print(input_x.shape)\n",
    "        array_lengths = torch.from_numpy(seq_length[i,0:int(num_files[i,])])\n",
    "        outputs = model_test(input_x, array_lengths)\n",
    "        outputs = torch.reshape(outputs, (outputs.shape[0], outputs.shape[1]))\n",
    "        b_factor[i,0:int(num_files[i,]),0:int(torch.max(array_lengths))] = outputs.to('cpu').numpy()\n",
    "  \n",
    "  return b_factor\n",
    "\n",
    "# ohe = ohe.to('cpu').numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making heat map for RC 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_cal(b_factor, ohe, input_sequence, num_files, seq_length):\n",
    "\n",
    "    filter = 7 ##THESE ARE VARIABLES. YOU CAN CHANGE THESE TO SUIT YOUR REQUIREMENTS. THIS DEFINES THE MAX(M) VALUE IN THE PAPER. MAX(M)=FILTER-1\n",
    "    stride = 1\n",
    "    rc = filter-1\n",
    "    heat_map = np.zeros((input_sequence.shape[0], len(amino_acid), len(amino_acid), rc, 2))\n",
    "\n",
    "\n",
    "    for prot in range(heat_map.shape[0]):\n",
    "        for fl in range(int(num_files[prot,])):\n",
    "            # print(num_files[prot,])\n",
    "            \n",
    "            subs_map = np.zeros((len(amino_acid), len(amino_acid), rc,2))\n",
    "            index = 0\n",
    "            conti = True \n",
    "            b_mean = np.mean(b_factor[prot,fl,0:int(seq_length[prot,fl])])\n",
    "            b_std =  np.std(b_factor[prot,fl,0:int(seq_length[prot,fl])])        \n",
    "                \n",
    "            while conti:\n",
    "                conv_unit = np.argmax(ohe[prot,fl,index:index+filter, :], axis=1)\n",
    "                b_unit = b_factor[prot,fl,index:index+filter]\n",
    "                look = np.arange(1,len(b_unit))\n",
    "                \n",
    "                for i in look:\n",
    "                    subs_map[conv_unit[0], conv_unit[i],i-1,0] += (( b_unit[0] - b_mean)/b_std)\n",
    "                    subs_map[conv_unit[0], conv_unit[i],i-1,1] += (( b_unit[i] - b_mean)/b_std)\n",
    "                    \n",
    "                index += stride\n",
    "                conti = ((index + filter) < seq_length[prot,fl])\n",
    "            \n",
    "            for m in range(rc):\n",
    "                heat_map[prot,:,:,m,:] += (subs_map[:,:,m,:]/(seq_length[prot,fl]-(m+1)))\n",
    "        \n",
    "        if num_files[prot,] != 0:   \n",
    "            heat_map[prot,:,:,:,:] =  heat_map[prot,:,:,:,:]/num_files[prot,]\n",
    "\n",
    "    heat_map = heat_map[:,0:len(amino_acid)-1,0:len(amino_acid)-1,:,:]       \n",
    "    \n",
    "    return heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_cals(heat_map, output_properties, id, num_files):\n",
    "    corr = np.zeros((heat_map.shape[1], heat_map.shape[2], heat_map.shape[3], heat_map.shape[4]))\n",
    "\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(corr.shape[1]):\n",
    "            for k in range(corr.shape[2]):\n",
    "                for l in range(corr.shape[3]):\n",
    "                    index = ((np.isnan(output_properties[:,id])==False) & (num_files != 0))\n",
    "                    pcc_prop = output_properties[index,id].reshape((1,-1))\n",
    "                    pcc_fea = heat_map[index,i,j,k,l].reshape((1,-1))\n",
    "                    if np.isnan(np.corrcoef(pcc_prop,pcc_fea)[0,1]):\n",
    "                        corr[i,j,k,l] = 0\n",
    "                    else:\n",
    "                        corr[i,j,k,l] = np.corrcoef(pcc_prop,pcc_fea)[0,1]\n",
    "    \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_cal(present, prop):\n",
    "    output_properties = np.zeros((len(present), 12))\n",
    "    count = 0\n",
    "    for ele in present:\n",
    "        pos = int(np.where(prop[:,0]==ele)[0])\n",
    "        output_properties[count,:] = prop[pos,1:13]\n",
    "        count += 1\n",
    "    return output_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng_cals(heat_map,feature_name, current):\n",
    "\n",
    "    good_features = 10000\n",
    "    # good_features = np.sum(corr>lim) + np.sum(corr<-lim)\n",
    "    feature_engineered = np.zeros((heat_map.shape[0], good_features))\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(heat_map.shape[1]):\n",
    "        for j in range(heat_map.shape[2]):\n",
    "            for k in range(heat_map.shape[3]):\n",
    "                for l in range(heat_map.shape[4]):\n",
    "                    name = current+ '_' +str(amino_acid[i])+ '_'  + str(amino_acid[j]) + '_'+ str(k+1) + '_'+str(l+1)\n",
    "                    if name in feature_name:\n",
    "                        feature_engineered[:,count] = heat_map[:,i,j,k,l]\n",
    "                        count += 1\n",
    "    \n",
    "    print(f'Number of features in spidroin {current} are', count)            \n",
    "   \n",
    "    return feature_engineered[:,0:count],feature_name[0:count, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in spidroin MaSp1 are 132\n",
      "Number of features in spidroin MaSp2 are 77\n",
      "Number of features in spidroin MaSp3 are 321\n",
      "Number of features in spidroin MaSp are 63\n",
      "Number of features in spidroin MiSp are 26\n",
      "Number of features in spidroin Spidroin are 206\n",
      "Shape of all_features (1, 825)\n"
     ]
    }
   ],
   "source": [
    "accepted_type = ['MaSp1', 'MaSp2', 'MaSp3', 'MaSp','MiSp', 'Spidroin']\n",
    "feature_names = np.load('./young_features_name.npy', allow_pickle=True)\n",
    "user_input = {'MaSp1': 'QSPVLGLVQQFSLGSKPDVSISTLCPEEPALKSTEPNDSFEYDVEFIPVFDSAANFVPVLPEIEEEIDLIDAEENAEEVVYRRTAPSFNLEDFENIFLLTLKDGGERIKFLTKALLKTKGQHSHNSLKLGHFVKKLSEVFGSMRYNNEYLTYSELYVQLLTETLIAALEIIRETDSSCLTVPSAPSELPQYVNALYNILI',\n",
    "              'MaSp2': None,\n",
    "              'MaSp3':None,\n",
    "              'MaSp':None,\n",
    "              'MiSp':None,\n",
    "              'Spidroin':None}\n",
    "all_features =  np.zeros((1, 10000))\n",
    "count = 0\n",
    "\n",
    "for i in range(len(accepted_type)):\n",
    "    spidroin = [accepted_type[i]]\n",
    "    seq = user_input[accepted_type[i]]\n",
    "    if seq is not None:\n",
    "        seq_len = len(list(seq))\n",
    "        input_sequence = np.zeros((1, 1, seq_len), dtype=object)\n",
    "        input_sequence[0,0,:] = list(seq)\n",
    "        num_files = np.ones((1,))\n",
    "        seq_length = np.ones((1,1))*seq_len\n",
    "        ohe = one_hot_encoding(input_sequence, num_files, seq_length)\n",
    "        b_factor = b_factor_cal(ohe, num_files, seq_length)\n",
    "        heat_map = rc_cal(b_factor, ohe, input_sequence, num_files, seq_length)\n",
    "        features, names  = feature_eng_cals(heat_map, feature_names,  accepted_type[i])\n",
    "        size = features.shape[1]\n",
    "        all_features[:,count:count+size] = features\n",
    "        count += size\n",
    "    else:\n",
    "        heat_map = np.zeros((1,len(amino_acid), len(amino_acid), 6, 2))\n",
    "        features, names  = feature_eng_cals(heat_map, feature_names,  accepted_type[i])\n",
    "        size = features.shape[1]\n",
    "        all_features[:,count:count+size] = features\n",
    "        count += size\n",
    "        \n",
    "\n",
    "all_features =  all_features[:,0:count]\n",
    "print('Shape of all_features', all_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction of property**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "network(\n",
       "  (nn): Sequential(\n",
       "    (0): Linear(in_features=825, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=24, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=24, out_features=12, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=12, out_features=8, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# CNN + RNN Model\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network, self).__init__()\n",
    "        \n",
    "        # nn layers\n",
    "        \n",
    "        self.nn = nn.Sequential(nn.Linear(825,128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(128,64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(64,24),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(24,12),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(12,8),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(8,1)\n",
    "                                )\n",
    "    \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # out3 = x3\n",
    "        # out5 = x5\n",
    "        out = self.nn(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = torch.load('./model/best.pth', map_location='cuda')\n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Youngs modulus 9.59\n"
     ]
    }
   ],
   "source": [
    "all_features = torch.from_numpy(all_features).to(device).type(dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_prop = model(all_features)\n",
    "    print('Predicted Youngs modulus', round(predicted_prop.item(),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98604b3b45ec6a06ff44cc545e23221fcb3349f85795d5ab7ba8ebf01f1c77b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
